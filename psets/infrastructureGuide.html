<!doctype html>
<html>
	<head>
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> 
	<!-- Bootstrap CSS --> 
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous"> 
	<meta charset="utf-8">
	<link href="style.css" rel="stylesheet">

	<link href="/psets/data/prism/prism.css" rel="stylesheet">

	<title> 
		
Управление роботом
 
	</title> 
	<link rel="icon" href="data/favicon.ico" type="image/x-icon">

	<!--- mathjax latex in html---->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
	<!--- mathjax end ---->

	</head>
	<body>
		<div class="container-sm">
			<!--	<div id=flex> -->
			<!--
			<nav>
				<ul>
					<li><a style="font-syze: 3em; font-weight: bold;" href="../index.html">Начало</a></li>
					<li> <a href="discassion.html">Обсуждение</a></li>
					<li><a href="error.html">Замечания</>
					<hr>

					<li><a href="code_cs50_io.html">Неделя 0</a> cs50.dev</li>
					<li><a href="functions.html">Неделя 1</a> Переменные и функции</a></li>
				</ul>
			</nav>
			-->
			<main>
				
<h1>Руководство</h1>
<p>Мы управляем реальным или смоделированным роботом 
с помощью программы Python под названием soar, 
которая работает на ноутбуке. Soar позволяет вам управлять 
 настоящим роботом или  симулятором, и позволяет управлять 
 с помощью джойстика или программы «brain».
brain управляет роботом, используя модель transducer 
(как описано в главе 1), что означает, что программа 
должна преобразовывать  входящие сенсорные сигналы 
в действия; это  будет выполняться несколько раз в секунду.
Вы можете запустить soar симулятор на своём компьютере,
но для управления роботом вам потребуется запустить 
его на одном из лабораторных ноутбуков.
Описания ниже применимы к лабораторным ноутбукам, но использование симулятора soar на вашем ноутбуке аналогично.
</p>

<h2>Сенсоры робота и действия</h2>
<p>Робот имеет несколько сенсоров (способы получать информацию 
о внешнем мире)
и действий (способов изменять состояние внешнего мира).
</p>
<h2>


<h3>Колеса</h3>
<p>
Робот имеет два ведущих колеса, по одному на каждой стороне,
и  поворотное колесо сзади.
Вы можете управлять роботами, указав скорость движения 
вперёд в метрах в секунду и скорость вращения 
в радианах в секунду.
</p>
<h3>Сенсоры</h3>
<p>
Роботы имеют восемь ультразвуковых преобразователей 
(сонары); это золотистые диски спереди.
Они посылают звуковые импульсы и прислушиваются к отражениям.
Сенсоры возвращают значения времени прохождения, то есть, 
сколько времени потребовалось звуку, чтобы вернуться.
Процессор робота преобразует их в оценки расстояния.
</p>
<p>
Когда сонары посылают звуковой импульс, существует период, 
известный как «период затухания», 
когда датчик все ещё вибрирует от генерации импульса и 
не может эффективно улавливать эхо.
Если объект находится настолько близко, что эхо возвращается 
в течение периода затухания, датчик не обнаружит объект.
Датчики, как правило, достаточно надёжны, 
если ближайший объект находится на расстоянии от 10 сантиметров 
до метра от робота.
Если датчик не обнаруживает эха, то расстояние 
далеко за пределами диапазона датчика.
</p>
<p>
В зависимости от материала объекта перед датчиком сонара 
звуковой импульс может отражаться в другом направлении, 
а не обратно к датчику.
Это также приведёт к тому, что датчик не сможет обнаружить объект.
Чтобы решить эту проблему, мы оклеили все наши «стены» 
пузырчатой плёнкой, из-за чего импульсы отражаются от 
стены во многих направлениях, 
что повышает вероятность того, что датчик обнаружит отражения.
</p>

<h3>Одометр</h3>
<p>
Робот имеет датчики вала на каждом из своих ведущих колёс, 
которые подсчитывают (доли) оборотов колёс.
Процессор робота использует эти данные датчика для 
обновления предполагаемой позы 
(термин, который означает как положение, так и ориентацию) 
робота в глобальной системе отсчёта.
</p>
<figure class="figure">
	<img src="/psets/data/images/odometry.png" class="figure-img img-fluid">
	<figcaption class="figure-caption"> 
		Рисунок 1. Глобальная система отсчёта одометрии
	</figcaption>
</figure>
<p>На рисунке 1 показана система отсчёта, 
в которой отображена одометрия робота.
Когда робота включили, система отчёта инициализируется так, 
что её начало находится в центре робота, 
а положительная ось X указывает на переднюю часть робота.
Теперь вы можете думать об этой системе отчёта, 
как о нарисованной на земле; 
когда вы перемещаете или вращаете робота, он продолжает 
сообщать о своей позе в этой системе отчёта.
</p>
<p>
Обратите внимание, что значение позы не изменится, 
если вы возьмёте настоящего робота и 
переместите его, не вращая колеса.
Он знает что движется только благодаря вращению колёс.
И помните, что одометрия далека от совершенства: 
колёса проскальзывают, и ошибка (особенно ошибка вращения) 
со временем увеличивается.
</p>

<h3>Аналого-цифровой интерфейс</h3>
<p>
Мы можем подключить к роботу дополнительные датчики и 
эффекторы через аналого-цифровой интерфейс.
Из робота выходит кабель, который обеспечивает подключение 
к четырём аналого-цифровым преобразователям (они позволяют 
нам преобразовывать напряжения на входных проводах в значения, 
которые можно прочитать с помощью программного обеспечения) 
и одному цифро-аналоговому преобразователю (этот позволяет 
нам преобразовать число, записанное в программном обеспечении, 
в выходное напряжение).
См. раздел 7.4 и раздел 7.5 для получения подробной информации 
об аппаратных подключениях этих входов.
</p>

<h2>Brains</h2>
<p>
soar brain имеет следующую структуру:
</p>
<pre>
<code class="language-python">
def setup():
	print("Loading brain")

def brainStart():
	print("Starting")

def step():
	print("Hello robot!")
def brainStop():
	print("Stopping")
</code>
</pre>
Процедура setup вызывается один раз,
когда brain файл считывается интерпретатором.
brainStart вызывается когда вы стартуете brain.
step вызывается снова и снова, несколько раз в секунду.
brain приведённый выше, если запущен, 
сначала напечатает Loading Brain,
когда вы загрузите (или перезагрузите) файл,
затем напечатает "Starting" при нажатии кнопки "Start"
на Soar, затем просто продолжит печатать "Hello robot!"
в окне сообщений soar, пока вы не остановите, после
чего будет распечатано "Stoping".
</p>
<p>
Обычно мы будем использовать конечные автоматы для управления 
нашими роботами. Вот очень простой мозг с контроллером 
конечного автомата:
<pre>
<code class="language-python">
import lib601.sm as sm
from soar.io import io

class MySMClass(sm.SM):
	def getNextValues(self, state, inp):
		return (None, io.Action(fvel = 0.1, rvel = 0))

def setup():
	robot.behavior = MySMClass()
	robot.behavior.start(verbose = True)

def step():
	robot.behavior.step(io.SensorInput()).execute()
</code>
</pre>
</p>
<p>Программа начинается с загрузки некоторых вспомогательных файлов.
Затем мы задали тривиальный автомат, 
который всегда генерирует на выходе действие, 
которое устанавливает скорость движения робота 
вперёд 0.1 м/с, а скорость его вращения — 0.
Мы будем называть behavior любой конечный автомат, 
который потребляет поток экземпляров класса SensorInput 
и создаёт поток экземпляров класса Action.
Обратите внимание, что и SensorInput, и Action 
определены в модуле soar под названием io, 
поэтому нам нужно добавить к ним префикс имени модуля. 
</p>
<p>Функция setup создаёт экземпляр MySMClass() behavior 
(если вы хотите использовать другой bihavior, 
вы создаёте его здесь) и запускает его.
verbose аргумент start приводит к печати входных, 
выходных данных и состояния SM; 
вы можете подавить печать, установив для этого аргумента значение 
False (или удалив необязательный  аргумент verbose из вызова).
</p>
<p>
Затем, наконец, в функции step мы вызываем io.SensorInput(), 
который создаёт экземпляр класса io.SensorInput, 
содержащий самые последние доступные данные датчиков.
Он передаётся в качестве входных данных методу step 
конечного автомата, который вызывает метод generateOutput, 
который возвращает экземпляр класса io.Action.
Наконец, мы вызываем execute этого действия, 
которое фактически отправляет команды роботу.
Если то, как написано, кажется запутанным, 
вот альтернативная версия, которая проясняет происходящее
</p>
<pre>
<code class="language-python">
def step():
	inp = io.SensorInput()
	act = robot.behavior.step(inp)
	act.execute()
</code>
</pre>
<p>Атрибуты экземпляра io.Action:
<ul> 
	<li>
		fvel: число задающее скорость вперёд в метрах в секунду.
		Положительное значение перемещает робота вперёд, 
		а отрицательное значение перемещает робота назад.
	</li>
	<li>
		rfel: одно действительное число, определяющее 
		скорость вращения в радианах в секунду. 
		Положительное число заставляет робота поворачивать 
		налево, а отрицательное число заставляет 
		робота поворачивать направо.
	</li>
	<li>
		voltage: одно число в диапазоне от 0 до 10, 
		определяющее напряжение, передаваемое на 
		цифро-аналоговый преобразователь
	</li>
</ul>
<p>
Передача этих трёх значений в инициализатор создаст новый
экземпляр. Вызов метода  execute() на экземпляр  Action
заставит робота выполнить это действие.
</p>
<p>
Атрибуты экземпляра io.SensorInput :
</p>
<ul>
	<li>
		sonars: список 8 значений от сонаров;
		расстояния измеряются в метрах; 
		причём крайний левый датчик имеет номер 0.
	</li>
	<li>
		odometry: экземпляр класса util.Pose, 
		который более подробно описан в 
		онлайн-документации к программному обеспечению.
	</li>
	<li>
		analogInputs: список из 4 значений аналого-цифровых 
		энкодеров в диапазоне от 0 до 10.
	</li>
</ul>
<p>
Только в симуляторе иногда может быть полезно «обмануть» и 
ссылаться на "фактические" координаты робота в глобальной 
системе координат симулятора 
(а не в системе одометрии, где находился робот в начале).
Если вы создадите экземпляр io.SensorInput так:
<pre>
<code class="language-python">
s = io.SensorInput(cheat = True)
</code>
</pre>
тогда значения одометрии будут представлять собой 
фактические координаты в симуляторе.
Выполнение этого действия на роботе приведёт к ошибке.
Ситуация, в которой использование cheat-позы имеет 
реальное отличие, — это когда вы перетаскиваете 
смоделированного робота по экрану:
обычная одометрия не знает, что робот переместился 
(поскольку колеса не вращались), но cheat-поза все 
равно будет точно знать, где он оказался.
Используйте это только для специальной отладки, 
потому что настоящие роботы не могут делать ничего подобного!
</p>

<h2>Использование Soar симулятора.</h2>
<p>
Чтобы использовать brain для управления симулированным 
роботом, сделайте следующее:
<ul>
	<li>
		Введите
		<pre>
		<code>
		>soar
		</code>
		</pre> 
		на приглашение в окне терминала на вашем компьютере. 
		Это должно вызвать soar  окно, которое показано на рисунке.
	</li>
	<figure class="figure">
		<img src="/psets/data/images/soar.png" class="figure-img img-fluid">
		<figcaption class="figure-caption"> 
			Soar окно
	</figcaption>
	<li>
		Нажмите на кнопку Simulator и выберите tutorial.py мир.
	</li>
	<li>
		Нажмите на Brain кнопку, используйте окно выбора
		файла, чтобы открыть smBrain.py.
	</li>
	<li>
		Нажмите кнопку Start.
	</li>
</ul>
<p>Робот поедет вперёд и распечатает некоторые данные в окне.
Чтобы остановить робота, нажмите кнопку «Stop». 
Не волнуйтесь, если он продолжит печатать какое-то время. 
Весь этот текст где-то хранится и ждёт печати.
</p>
<p>Обычно, вы определяете soar brain в файле и загружаете 
его в soar.
Если при загрузке мозга произошла ошибка, вы увидите 
сообщение об ошибке (красным цветом). 
Если вам нужно отредактировать файл brain, вы можете 
отредактировать его в редакторе, а затем приказать Soar 
перезагрузить мозг, нажав кнопку «reload brain».
Reload Brain and World кнопка также перезагрузит мозг, 
а в симуляторе вернёт робота в исходную позу.
На Pioneer перезагрузка мира приведёт к сбросу 
последовательного соединения с роботом, в результате 
чего робот сбросит свою одометрию в исходное положение.
</p>
<p>
Что касается сонаров на симуляторе, вы увидите линии, 
выступающие из робота в различных точках: 
они представляют собой пути прохождения 
сигналов датчиков сонаров.
Эти смоделированные датчики следуют идеальной модели: 
они всегда измеряют расстояние (с небольшим 
количеством добавленного случайного шума) 
по лучу до первой поверхности, с которой они соприкасаются.
Линия рисуется красным, когда сонар не обнаруживает отражения. 
В симуляторе можно брать и перетаскивать робота 
мышкой во время работы мозга и смотреть, как меняются показания.
</p>
<p>
Вы можете заметить, что смоделированный робот иногда 
становится красным.
Это означает, что он находится рядом со стенами или 
сталкивается с ними. 
Если он застрял и вы посылаете ему команды двигаться вперёд, 
ничего не произойдёт.
Однако вы все равно можете двигать назад или поворачивать его.
</p>		

<h2>Использование робота Pioner</h2>
<p>Вы можете подключить робота к лабораторному ноутбуку, 
(1) подключив короткий синий USB-кабель-адаптер к ноутбуку, 
(2) подключив USB-адаптер к одному концу последовательного кабеля и 
(3) подключив другой конец последовательный кабель к 
последовательному разъёму на роботе, который находится 
рядом с панелью с выключателем питания и световыми 
индикаторами на боковой стороне робота.
</p>

<p>Перед подключением обязательно завяжите последовательный 
кабель простым узлом вокруг ручки на задней стороне робота. 
Это обеспечит разгрузку от натяжения и не позволит 
последовательному кабелю отсоединиться от робота или 
погнуть разъём, если его потянуть.
</p>
<p>Начните с включения робота. Чтобы управлять роботом 
с помощью джойстика, нажмите Pioneer и Joystick, а затем Start. 
Щелчком и перетаскиванием в появившемся окне джойстика можно 
управлять скоростью движения вперёд и вращения робота.
</p>

<h3>Советы</h3>
<p>
Для запуска робота:
<ul>
	<li>
		Собираясь запустить робота, убедитесь, что робот 
		включён и последовательный кабель подключён с 
		обоих концов.
	</li>
	<li> 
		Роботы довольно крепкие, но (а) падение их или 
		(б) столкновение со стеной может их повредить. 
		Пожалуйста, будьте осторожны. Если робот начнёт 
		убегать от вас, схватите его, поднимите и 
		выключите питание.
	</li>
	<li>
		Иногда вы можете выполнить базовую отладку, 
		наклонив робота сзади так, чтобы его колеса 
		были подняты в воздух, чтобы вы могли видеть, 
		как колеса вращаются (и в каком направлении), 
		но робот фактически не движется.
	</li>
	<li> 
		Если робот выглядит полностью мёртвым, то есть 
		при включении питания не горят индикаторы, возможно, 
		перегорел предохранитель. Поговорите с сотрудником.
	</li>
	<li> 
		Если вам не повезло, попробуйте этот процесс: 
		<ul>
			<li>Прекратите soar и выключите робота; </li> 
			<li>Перезапустите soar и включите робота;</li>
			<li> После этого выберите значок робота в 
				soar; затем</li>
			<li>Прислушайтесь к тикающему звуку сонаров.</li>
		</ul>
	</li>
	<li> 
		Если по какой-то причине последовательный 
		кабель отсоединился, выполните описанную 
		выше процедуру.

	</li>
</ul>

<h2>Трассировка и построение графиков</h2>
<p>В Soar есть средства для выполнения различных видов 
трассировки и построения графиков для отладки ваших 
программ и документирования результатов. Здесь мы опишем 
эти средства.
</p>

<h3>Видеть то, что видит робот</h3>
<p>Часто важно знать, что говорят датчики робота, 
чтобы понять, почему робот ведёт себя именно так, 
или задокументировать результат эксперимента.
Для этого есть несколько полезных инструментов. 
Чтобы использовать многие из этих инструментов, 
вам необходимо создать экземпляр RobotGraphics в вашей функции start.
Обычно это будет выглядеть так:
<pre>
<code class="language-python">
def setup():
	robot.gfx = gfx.RobotGraphics(sonarMonitor = True, 
	drawSlimeTrail = True)
	</code>
	</pre>
</p>
<p>slime trails (след слизи) и static plots (описанные ниже) будут рисоваться, 
когда soar остановлен.
Это всегда делается, когда вы нажимаете кнопку Stop в soar, 
но если вы хотите, чтобы brain soar автоматически останавливал, 
когда контрольное состояние достигнуто, вы можете добавить 
следующую строку в step функцию:
<pre>
<code class="language-python">
io.done(robot.behavior.isDone())
</code>
</pre>
</p>

<h2>Монитор сонара</h2>
<figure class="figure">
	<img src="/psets/data/images/sonar.png" class="figure-img img-fluid">
</figure>

<p>
Просмотр показаний сонара робота в режиме реального времени 
может быть полезен либо для обнаружения проблем с оборудованием, 
либо в качестве инструмента отладки для лучшего понимания 
поведения вашего brain.
Монитор сонара, показанный выше, обеспечивает графическое 
отображение показаний сонара робота, независимо от того, 
подключено ли Soar к симулятору робота или к Pioneer.
Как и сонары в симуляторе, сонары представлены чёрной линией, 
которая становится красной, когда сонар вообще не слышит эха.
</p>

<h2>Slime trails(След слизи)</h2>
<p>
Часто полезно знать, где находился робот во время выполнения.
Мы не можем знать это точно на реальном роботе, 
но можем получить некоторое представление о том, что происходит, 
глядя на позу, сообщаемую одометрией.
Мы делаем это, рисуя «slime trail» пути робота, 
как если бы это была улитка.
Цвет тропы постоянно меняется вдоль неё, чтобы дать 
вам представление о времени, когда были заняты определённые места.
На рисунке 2 показан пример следа слизи.
</p>
<figure class="figure">
	<img src="/psets/data/images/slime.png" class="figure-img img-fluid">
	<figcaption class="figure-caption"> 
		Рисунок 2. Слизистый след робота, идущего за стеной, 
		в мире обучающего симулятора.
	</figcaption>
</figure>

<p>Если для аргумента drawSlimeTrail конструктора RobotGraphics 
установлено значение True, окно следа слизи появится, 
когда мозг перестанет работать.
Если вы работаете на симуляторе, вы можете установить для 
drawSlimeTrail значение «Cheat», и при этом будет использоваться 
истинное положение робота, а не внутренние измерения 
одометрии робота, так что при перетаскивании робота 
след слизи будет показывать движение.
</p>

<h2>Динамическое построение графиков</h2>
<p>
Другой полезный инструмент, виртуальный осциллограф, 
в реальном времени отображает график некоторой 
произвольной функции значений датчиков робота.
Функция addDynamicPlotFunction принимает кортеж (name, function), 
где name — это строка, отображаемая в легенде, а function — это 
функция, которая принимает экземпляр SensorInput и возвращает число.
</p>
<figure class="figure">
	<img src="/psets/data/images/oscilloscope.png" class="figure-img img-fluid">
</figure>
<p>
На рисунке показано окно осциллографа, на котором отображается 
минимальное расстояние, сообщаемое двумя крайними правыми 
датчиками сонара ("right dist"), и среднее расстояние, 
сообщаемое двумя передними сонаром ("front dist").
Мы создаём эти графики, добавляя следующие строки в функцию setup.
</p>
<pre>
<code class = "language-python">
robot.gfx.addDynamicPlotFunctions(('right dist',
	lambda inp: min(inp.sonars[6:])))
robot.gfx.addDynamicPlotFunctions(('front dist',
	lambda imp: sum(inp.sonars[3:5])/2.0))
	</code>
</pre>
<p>Кнопка Configure Oscilloscope позволяет настроить границы 
осей и метки на графике.
По умолчанию границы оси y представляют собой минимальное и 
максимальное значение y, наблюдаемое на данный момент.
</p>
<p>
Также возможно построить график нескольких сигналов 
одним вызовом addDynamicPlotFunction, предоставив список имён 
и функцию, которая возвращает список значений.
Например, этот код будет отображать первые три аналоговых 
входных сигнала, присваивая каждому сигналу имя, 
соответствующее устройству, к которому он будет 
подключён в лаборатории схем:
</p>
<pre>
<code class="language-python">
robot.gfx.addDynamicPlotFunction((['neck', 'left', 'right'],
	lambda inp: inp.analogInputs[0:3]))
</code>
</pre>
<p>
Хотя динамическое построение графиков может быть очень 
полезным инструментом отладки, иногда вам придётся 
отключить его, чтобы добиться оптимальной 
производительности вашего мозга, поскольку графические 
задачи могут потреблять много вычислительных циклов.
</p>

<h2>Статическое построение графиков</h2>
<p>
Иногда вам может потребоваться построить сигнал 
как функцию другого сигнала, а не как функцию времени.

Кроме того, вы можете захотеть создать графики нескольких 
сигналов на разных осях, если их величины значительно различаются.

Или вы можете обнаружить, что построение графиков в реальном 
времени занимает слишком много времени на каждом 
этапе и заставляет ваш brain работать странно.

В этих случаях вместо этого вы можете использовать 
статическое построение графиков, которое просто 
сохранит значения, которые вы хотите отобразить, а 
затем сгенерирует окно графика для каждой функции, 
когда brain остановится.
</p>

<p>
Класс RobotGraphics предоставляет addStatic-PlotFunction, 
который аналогичен addDynamic-PlotFunction, за исключением 
того, что он может принимать два разных сигнала, 
поэтому важно указать, какой из них является сигналом оси X, 
а какой — сигналом оси Y.

Если аргумент x не предоставлен, по умолчанию сигнал 
отображается как функция количества шагов.
</p>
<figure class="figure">
	<img src="/psets/data/images/staticPlot.png" class="figure-img img-fluid">
</figure>

<p>Код ниже, помещённый в функцию start, создаст график, 
подобный показанному на рисунке: интенсивность света в левом 
глазу робота как функция угла робота относительно 
его первоначальной ориентации.

Аргумент ConnectPoints — это логическое значение, определяющее, 
следует ли рисовать линию между каждой точкой на графике.
</p>
<pre>
<code class="language-python">
startTheta = io.SensorInput().odometry.theta
robot.gfx.addStaticPlotFunction(
	x=('angle', lambda inp: sartTheta-inp.odometry.theta),
	y=('left eye', lambda inp: inp.analogInputs[1]),
	conectPoints=True)
	</code>
</pre>





			</main>
		</div>




		<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous">
		</script> 
		<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous">
		</script> 
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous">
		</script>

		<script src="/psets/data/prism/prism.js"></script>
	</body>
</html>